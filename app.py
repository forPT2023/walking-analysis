import os
import streamlit as st
import cv2
import numpy as np
import tempfile
import mediapipe as mp
import pandas as pd
import plotly.express as px
from supabase import create_client, Client
import openai
import json

# âœ… ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# âœ… ç’°å¢ƒå¤‰æ•°ãŒå–å¾—ã§ãã¦ã„ãªã„å ´åˆã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
if not SUPABASE_URL or not SUPABASE_KEY or not OPENAI_API_KEY:
    st.error("âŒ ç’°å¢ƒå¤‰æ•°ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼Render ã¾ãŸã¯ Streamlit Cloud ã® Environment Variables ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# âœ… Supabase ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆ
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

# âœ… OpenAI API ã‚­ãƒ¼ã®è¨­å®š
openai.api_key = OPENAI_API_KEY

# âœ… Mediapipe ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
mp_pose = mp.solutions.pose
mp_drawing = mp.solutions.drawing_utils

# âœ… ãƒšãƒ¼ã‚¸è¨­å®šã§ãƒ¢ãƒã‚¤ãƒ«è¡¨ç¤ºã‚’æœ€é©åŒ–
st.set_page_config(
    page_title="æ­©è¡Œåˆ†æã‚¢ãƒ—ãƒª",
    page_icon="ğŸš¶â€â™‚ï¸",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# âœ… ã‚«ã‚¹ã‚¿ãƒ CSS
st.markdown("""
    <style>
    .stApp {
        max-width: 100%;
        padding: 1rem;
    }
    .uploadedFile {
        margin: 1rem 0;
    }
    .stButton>button {
        width: 100%;
        margin: 1rem 0;
    }
    </style>
""", unsafe_allow_html=True)

# âœ… Webã‚¢ãƒ—ãƒªã®ã‚¿ã‚¤ãƒˆãƒ«
st.title("ğŸš¶â€â™‚ï¸ æ­©è¡Œåˆ†æã‚¢ãƒ—ãƒª")

# âœ… èª¬æ˜æ–‡ã‚’expanderã«æ ¼ç´ã—ã¦ã‚¹ãƒšãƒ¼ã‚¹ã‚’ç¯€ç´„
with st.expander("ğŸ“± ä½¿ã„æ–¹ã‚’è¦‹ã‚‹"):
    st.write("""
    1. æ­©è¡Œå‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™
    2. ã€Œæ­©è¡Œè§£æã‚’é–‹å§‹ã€ãƒœã‚¿ãƒ³ã‚’ã‚¿ãƒƒãƒ—ã—ã¾ã™
    3. è§£æçµæœãŒè¡¨ç¤ºã•ã‚Œã‚‹ã¾ã§ãŠå¾…ã¡ãã ã•ã„
    """)

# âœ… å‹•ç”»ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
uploaded_file = st.file_uploader("æ­©è¡Œå‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ ğŸ“¸", type=["mp4", "mov"])

if uploaded_file:
    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
    temp_file.write(uploaded_file.read())

    cap = cv2.VideoCapture(temp_file.name)

    # âœ… ä¿å­˜ç”¨ã®å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
    output_video_path = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4").name
    fourcc = cv2.VideoWriter_fourcc(*"mp4v")
    fps = max(1, int(cap.get(cv2.CAP_PROP_FPS)))
    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))

    if st.button("ğŸ‘‰ æ­©è¡Œè§£æã‚’é–‹å§‹"):
        with st.spinner("ğŸ”„ è§£æä¸­..."):
            joint_data = []

            JOINTS = {
                "LEFT_HIP": mp_pose.PoseLandmark.LEFT_HIP,
                "RIGHT_HIP": mp_pose.PoseLandmark.RIGHT_HIP,
                "LEFT_KNEE": mp_pose.PoseLandmark.LEFT_KNEE,
                "RIGHT_KNEE": mp_pose.PoseLandmark.RIGHT_KNEE,
                "LEFT_ANKLE": mp_pose.PoseLandmark.LEFT_ANKLE,
                "RIGHT_ANKLE": mp_pose.PoseLandmark.RIGHT_ANKLE
            }

            with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:
                while cap.isOpened():
                    ret, frame = cap.read()
                    if not ret:
                        break

                    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    results = pose.process(image)

                    if results.pose_landmarks:
                        frame_data = {"Time (s)": cap.get(cv2.CAP_PROP_POS_FRAMES) / fps}
                        for joint_name, joint_id in JOINTS.items():
                            landmark = results.pose_landmarks.landmark[joint_id]
                            frame_data[f"{joint_name}_Y"] = landmark.y

                        joint_data.append(frame_data)
                        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)

                    out.write(cv2.cvtColor(image, cv2.COLOR_RGB2BGR))

            cap.release()
            out.release()

            df = pd.DataFrame(joint_data)
            st.success("âœ… è§£æå®Œäº†ï¼")

            # âœ… ã‚¿ãƒ–ã§çµæœã‚’æ•´ç†
            tab1, tab2, tab3 = st.tabs(["ğŸ“Š ã‚°ãƒ©ãƒ•", "ğŸ¥ å‹•ç”»", "ğŸ“ è§£èª¬"])
            
            with tab1:
                # âœ… ã‚°ãƒ©ãƒ•ã‚’æœ€é©åŒ–
                fig = px.line(df, x="Time (s)", 
                            y=["LEFT_KNEE_Y", "RIGHT_KNEE_Y", "LEFT_ANKLE_Y", "RIGHT_ANKLE_Y"],
                            title="æ­©è¡Œãƒãƒ©ãƒ³ã‚¹ã®å¤‰åŒ–",
                            labels={"value": "é–¢ç¯€ã®é«˜ã•", "variable": "é–¢ç¯€"})
                fig.update_layout(
                    height=400,
                    margin=dict(l=10, r=10, t=30, b=10),
                    legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
                )
                st.plotly_chart(fig, use_container_width=True)

            with tab2:
                st.video(output_video_path)
                with open(output_video_path, "rb") as file:
                    st.download_button(
                        "ğŸ“¥ è§£æå‹•ç”»ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        file,
                        file_name="walking_analysis.mp4",
                        mime="video/mp4",
                        use_container_width=True
                    )

            with tab3:
                # âœ… ã‚¹ã‚³ã‚¢è¨ˆç®—
                def calculate_gait_scores(df):
                    scores = {}
                    scores["Stability Score"] = max(0, 100 - (df["LEFT_KNEE_Y"].std() + df["RIGHT_KNEE_Y"].std()) * 50)
                    step_intervals = np.diff(df["Time (s)"])
                    scores["Gait Rhythm Score"] = max(0, 100 - np.std(step_intervals) * 500)
                    scores["Symmetry Score"] = max(0, 100 - np.mean(np.abs(df["LEFT_KNEE_Y"] - df["RIGHT_KNEE_Y"])) * 500)
                    return scores

                scores = calculate_gait_scores(df)
                
                # âœ… ã‚¹ã‚³ã‚¢ã‚’ã‚«ãƒ¼ãƒ‰å½¢å¼ã§è¡¨ç¤º
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("å®‰å®šåº¦", f"{scores['Stability Score']:.1f}")
                with col2:
                    st.metric("ãƒªã‚ºãƒ ", f"{scores['Gait Rhythm Score']:.1f}")
                with col3:
                    st.metric("å¯¾ç§°æ€§", f"{scores['Symmetry Score']:.1f}")

                # âœ… AIè§£æ
                def generate_ai_analysis(scores_json):
                    prompt = f"""
                    ã‚ãªãŸã¯æ­©è¡Œè§£æã®å°‚é–€å®¶ã§ã™ã€‚
                    ä»¥ä¸‹ã®è§£æçµæœã‚’ç°¡æ½”ã«ã‚ã‹ã‚Šã‚„ã™ãè§£èª¬ã—ã¦ãã ã•ã„ï¼š
                    {json.dumps(scores_json, indent=2, ensure_ascii=False)}
                    """

                    response = openai.ChatCompletion.create(
                        model="gpt-3.5-turbo",
                        messages=[
                            {"role": "system", "content": "ã‚ãªãŸã¯æ­©è¡Œè§£æã®å°‚é–€å®¶ã§ã™ã€‚"},
                            {"role": "user", "content": prompt}
                        ]
                    )
                    return response["choices"][0]["message"]["content"]

                with st.spinner("AIè§£æä¸­..."):
                    ai_analysis = generate_ai_analysis(scores)
                    st.write(ai_analysis)